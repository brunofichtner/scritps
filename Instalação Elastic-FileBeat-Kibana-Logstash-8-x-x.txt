# instale as bibliotecas 
apt -y install wget ntp apt-transport-https gnupg unzip curl net-tools default-jre tcpdump

wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch |  apt-key add -
echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" |  tee -a /etc/apt/sources.list.d/elastic-8.x.list

#Instalando elastic search
wget --no-check-certificate https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.5.2-amd64.deb
 dpkg -i elasticsearch-8.5.2-amd64.deb
 systemctl daemon-reload
 systemctl enable elasticsearch.service
 systemctl start elasticsearch.service
 systemctl status elasticsearch.service
 curl -X GET 127.0.0.1:9200
	
# Agora vamos editar o arquivo de configuração do elasticsearch.yml
 nano /etc/elasticsearch/elasticsearch.yml
 
cluster.name: flow-huawei-mikrotik-cisco-juniper-frr
node.name: flow-01
network.host: IP DO SERVIDOR
http.port: 9200
#discovery.seed_hosts: ["127.0.0.1"]
#cluster.initial_master_nodes: ["127.0.0.1"]

#discovery.type: 'single-node
#"indices.query.bool.max_clause_count: 8192"
#"search.max_buckets: 250000"

# Opcional

 #nano jvm.options
dicione o arquivo e defina e heap.optionsa cerca de um terço da memória do sistema, mas não exceda . Para este exemplo, usaremos 12 GB dos 32 GB de memória disponíveis para heap da JVM.

# echo -e "-Xms12g\n-Xmx12g" > /etc/elasticsearch/jvm.options.d/heap.options
1
# echo -e "-Xms12g\n-Xmx12g" > /etc/elasticsearch/jvm.options.d/heap.options
Os limites do sistema aumentados devem ser especificados em um systemd.

# mkdir /etc/systemd/system/elasticsearch.service.d
# cat <<EOF >/etc/systemd/system/elasticsearch.service.d/elasticsearch.conf
[Service]
LimitNOFILE=131072
LimitNPROC=8192
LimitMEMLOCK=infinity
LimitFSIZE=infinity
LimitAS=infinity
EOF

systemctl daemon-reload
systemctl restart elasticsearch.service
systemctl enable elasticsearch.service


 wget --no-check-certificate https://artifacts.elastic.co/downloads/kibana/kibana-8.5.1-amd64.deb
 
  dpkg -i kibana-8.1.1-amd64.deb
  
  nano /etc/kibana/kibana.yml
  server.port: 5601
  server.host: "100.100.20.9"
  server.name: "kibana-flow"
  elasticsearch.hosts: ["http://127.0.0.1:9200"]



  systemctl enable kibana.service
  systemctl start kibana.service
  114  systemctl status kibana.service
  115  tail -f /var/log/kibana/kibana.log -n 1000



wget --no-check-certificate https://artifacts.elastic.co/downloads/logstash/logstash-8.5.2-amd64.deb

 dpkg -i logstash-8.5.2-amd64.deb
 
 /usr/share/logstash/bin/logstash-plugin install logstash-codec-sflow
 /usr/share/logstash/bin/logstash-plugin update logstash-codec-netflow
 /usr/share/logstash/bin/logstash-plugin update logstash-input-udp
 /usr/share/logstash/bin/logstash-plugin update logstash-input-tcp
 /usr/share/logstash/bin/logstash-plugin update logstash-filter-dns
 /usr/share/logstash/bin/logstash-plugin update logstash-filter-geoip
 /usr/share/logstash/bin/logstash-plugin update logstash-filter-translate
 
 nano /etc/logstash/logstash.yml
 nano /etc/logstash/pipelines.yml
  
systemctl daemon-reload
systemctl enable logstash
systemctl start logstash

# FileBeat

wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch |  apt-key add -
echo "deb https://artifacts.elastic.co/packages/8.x/apt stable main" |  tee -a /etc/apt/sources.list.d/elastic-8.x.list

wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.5.1-amd64.deb

 dpkg -i filebeat-8.5.1-amd64.deb

# acessar arquivo de configuração do filebeat  /etc/filebeat/filebeat.yml e alterar endereço IP do elastic e kibana

# ---------------------------- Elasticsearch Output ----------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["10.255.255.244:9200"]
  
   # Kibana Host
   host: "10.255.255.244:5601"


 apt-get update &&  apt-get install filebeat
 systemctl enable filebeat
 update-rc.d filebeat defaults 95 10
 filebeat modules enable netflow
 filebeat setup
 service filebeat start
 systemctl restart elasticsearch.service
 
doc_table:highlight
Pin filters by default
Store URLs in session storage
 
 #huawei
ip netstream timeout active 1
ip netstream timeout inactive 15
ip netstream export version 9 origin-as
ip netstream export index-switch 32
ip netstream export template timeout-rate 1
ip netstream sampler fix-packets 1000 inbound
ip netstream sampler fix-packets 1000 outbound
ip netstream export source LOOPBACK
ip netstream export host ELASTICSEARCH 2055
ip netstream export template option sampler

# acessar interface uplink e adicionar comandos abaixo:
 ip netstream inbound
 ip netstream outbound


# CISCO
flow record NETFLOW_RECORD
match ipv4 tos
match ipv4 protocol
match ipv4 source address
match ipv4 destination address
match transport source-port
match transport destination-port
match interface input
collect interface output
collect counter bytes
collect counter packets
!

!
flow exporter NETFLOW_EXPORT
destination X.X.X.X
source FastEthernet0/1/0
transport udp 2055
export-protocol netflow-v5


flow record PP-NETFLOW-REC
		match ipv4 tos
		match ipv4 protocol
		match ipv4 source address
		match ipv4 destination address
		match transport source-port
		match transport destination-port
		match interface input
		collect interface output
		collect counter bytes
		collect counter packets
	!
	flow exporter PP-NETFLOW-EXP
		destination [IP_DO_SERVIDOR_NETFLOW] vrf Mgmt-PP
		source Port-channel1.3920
		transport udp {porta} 
	!
	flow monitor PP-NETFLOW-MONITOR
		exporter PP-NETFLOW-EXP
		record PP-NETFLOW-REC
		cache timeout active 60
!
interface Port-channel1.[SUB-INTERFACE-ID]
ip flow monitor PP-NETFLOW-MONITOR input
ip flow monitor PP-NETFLOW-MONITOR output
